{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYfs35JsF9pE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import Adam\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "M4sWIo_wHxdK",
        "outputId": "870bbacb-6f0f-4b29-d867-02a9027ae292"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/NER/ner_dataset.csv', encoding='unicode_escape')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hHKqOig-1sS"
      },
      "source": [
        "df = df.fillna(method='ffill')\n",
        "df = df.applymap(str.lower)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkyiyUiq--kd"
      },
      "source": [
        "class Sentence(object):\n",
        "  def __init__(self, df):\n",
        "    self.n_sent = 1\n",
        "    self.df = df\n",
        "    self.empty = False\n",
        "    agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), s['POS'].values.tolist(), s['Tag'].values.tolist())]\n",
        "    self.grouped = self.df.groupby('Sentence #').apply(agg)\n",
        "    self.sentences = [s for s in self.grouped]\n",
        "\n",
        "  def get_text(self):\n",
        "    try:\n",
        "      s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "      self.n_sent += 1\n",
        "      return s\n",
        "    except:\n",
        "      return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ooTExgMAlqe"
      },
      "source": [
        "getter = Sentence(df)\n",
        "sentences = getter.sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRPUIioQCBN0"
      },
      "source": [
        "max_len = max(len(s) for s in sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1sC0xxxEJMU"
      },
      "source": [
        "words = list(df['Word'].unique())\n",
        "tags = list(df['Tag'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDn9-7piEPBr"
      },
      "source": [
        "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "word2idx['UNK'] = 1\n",
        "word2idx['PAD'] = 0\n",
        "\n",
        "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
        "tag2idx['PAD'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSLGkjwCFTVF"
      },
      "source": [
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "idx2tag = {i: t for t, i in tag2idx.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqjeiKvtHvC5"
      },
      "source": [
        "X = [torch.tensor([word2idx[w[0]] for w in s]) for s in sentences]\n",
        "X = pad_sequence(sequences = X, batch_first = True, padding_value = word2idx[\"PAD\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghLTPXGVMPmt"
      },
      "source": [
        "y = [torch.tensor([tag2idx[w[2]] for w in s]) for s in sentences]\n",
        "y = pad_sequence(sequences = y, batch_first = True, padding_value = tag2idx[\"PAD\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqYFeE6LF6i-"
      },
      "source": [
        "num_tags = df['Tag'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzR-bzpLv2FA"
      },
      "source": [
        "#train test split\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.10)\n",
        "\n",
        "trainset = list(zip(X_train, y_train))\n",
        "validationset = list(zip(X_validation, y_validation))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "validationloader = torch.utils.data.DataLoader(validationset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfUB242_T4ow",
        "outputId": "9d7f7b96-e479-47b7-e7a5-0e3f8193f5cf"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ2juladV67Z"
      },
      "source": [
        "def progress(value:int, max:int=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 50%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "        {value} / {max}\n",
        "    \"\"\".format(value=value, max=max))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFB66qAb2ND4"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, lstm_layers,\n",
        "               emb_dropout, lstm_dropout, fc_dropout):\n",
        "    super().__init__()\n",
        "    #embedding layer\n",
        "    self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "    self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "    #BiLSTM\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=lstm_layers, bidirectional=True, dropout=lstm_dropout if lstm_layers > 1 else 0)\n",
        "    \n",
        "    #Fully Connected\n",
        "    self.fc_dropout = nn.Dropout(fc_dropout)\n",
        "    self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    embedding_out = self.emb_dropout(self.embeddings(inputs))\n",
        "    lstm_out, _ = self.lstm(embedding_out)\n",
        "    ner_out = self.fc(self.fc_dropout(lstm_out))\n",
        "    return ner_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxunzMO8NlzZ"
      },
      "source": [
        "model = BiLSTM(\n",
        "    vocab_size=len(words) + 2, \n",
        "    embedding_dim=int(len(words) ** 0.56), \n",
        "    hidden_dim=64, \n",
        "    output_dim=len(tags)+1, \n",
        "    lstm_layers=2, \n",
        "    emb_dropout=0.5, \n",
        "    lstm_dropout=0.1, \n",
        "    fc_dropout=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoycuWGqUPas"
      },
      "source": [
        "class NER(object):\n",
        "  def __init__(self, model, trainloader, validationloader, optimizer_cls, loss_fn_cls):\n",
        "    self.model = model\n",
        "    self.trainloader = trainloader\n",
        "    self.validationloader = validationloader\n",
        "    self.optimizer = optimizer_cls(model.parameters())\n",
        "    #ignored padding to contribute to the input gradient\n",
        "    self.loss_fn = loss_fn_cls(ignore_index=0)\n",
        "\n",
        "  def evaluate(self):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    validation_size = len(self.validationloader)\n",
        "    display_out = display(progress(0, self.validationloader), display_id=True)\n",
        "\n",
        "    self.model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(self.validationloader, 0):\n",
        "        text, tag = data\n",
        "        pred_tags = model(text)\n",
        "        pred_tags = pred_tags.view(-1, pred_tags.shape[-1])\n",
        "        true_tags = tag.view(-1)\n",
        "        loss = self.loss_fn(pred_tags, true_tags)\n",
        "        accuracy = self.accuracy(i, pred_tags, true_tags)\n",
        "\n",
        "        '''\n",
        "        evaluate\n",
        "        '''\n",
        "        _, predicted = torch.max(pred_tags, 1)\n",
        "        non_pad_idx = (true_tags != 0).nonzero(as_tuple = True)\n",
        "        correct = predicted[non_pad_idx].eq(true_tags[non_pad_idx])\n",
        "        accuracy = correct.sum() / torch.FloatTensor([true_tags[non_pad_idx].shape[0]])\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_accuracy += accuracy.item()\n",
        "\n",
        "        display_out.update(progress(i+1, validation_size))\n",
        "\n",
        "      return epoch_loss / len(self.validationloader), epoch_accuracy / len(self.validationloader)\n",
        "\n",
        "\n",
        "  def epoch(self):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    train_size = len(self.trainloader)\n",
        "    display_out = display(progress(0, train_size), display_id=True)\n",
        "\n",
        "    self.model.train()\n",
        "\n",
        "    torch.set_printoptions(profile='full')\n",
        "    for i, data in enumerate(self.trainloader, 0):\n",
        "      text, tag = data\n",
        "      #zero the parameter gradients\n",
        "      self.optimizer.zero_grad()\n",
        "\n",
        "      pred_tags = model(text)\n",
        "      pred_tags = pred_tags.view(-1, pred_tags.shape[-1])\n",
        "      true_tags = tag.view(-1)\n",
        "      loss = self.loss_fn(pred_tags, true_tags)\n",
        "      accuracy = self.accuracy(pred_tags, true_tags)\n",
        "\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_accuracy += accuracy.item()\n",
        "\n",
        "      display_out.update(progress(i+1, train_size))\n",
        "\n",
        "    return epoch_loss / len(self.trainloader), epoch_accuracy / len(self.trainloader)\n",
        "\n",
        "  def accuracy(self, preds, actual):\n",
        "    _, predicted = torch.max(preds, 1)\n",
        "    non_pad_idx = (actual != 0).nonzero(as_tuple = True)\n",
        "    correct = predicted[non_pad_idx].eq(actual[non_pad_idx])\n",
        "    return correct.sum() / torch.FloatTensor([actual[non_pad_idx].shape[0]])\n",
        "\n",
        "  def train(self, n_epochs:int):\n",
        "    for i in range(n_epochs):\n",
        "      print(f'Epoch {i+1}')\n",
        "      print('Training Phase')\n",
        "      train_loss, train_accuracy = self.epoch()\n",
        "      print(f\"\\t\\tTrain Loss: {train_loss:.5f} | Train Accuracy: {train_accuracy: .5f}\")\n",
        "      print('Validation Phase')\n",
        "      eval_loss, eval_accuracy = self.evaluate()\n",
        "      print(f\"\\t\\tValidation Loss: {eval_loss:.5f} | Validation Accuraccy: {eval_accuracy: .5f}\")\n",
        "\n",
        "  def predict(self, sentence:str, actual_tags:list=[], display=True):\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "    tokens = [token.lower() for token in tokenizer(sentence)]\n",
        "    tok2idx = torch.IntTensor([[word2idx[t] if t in word2idx else word2idx['UNK'] for t in tokens]])\n",
        "    pred_tags = self.model(tok2idx)\n",
        "    pred_tags = pred_tags.view(-1, pred_tags.shape[-1])\n",
        "    _, predicted = torch.max(pred_tags, 1)\n",
        "\n",
        "    if display:\n",
        "      if len(actual_tags) != 0:\n",
        "        print('\\t{:<10} {:>15} {:>10}'.format('words', 'predicted', 'actual'))\n",
        "        for t, p, at in zip(tokens, predicted, actual_tags):\n",
        "          print('\\t{:<10} {:>15} {:>10}'.format(t, idx2tag[p.item()], at))\n",
        "      else :\n",
        "        print('\\t{:<10} {:>15}'.format('words', 'predicted'))\n",
        "        for t, p in zip(tokens, predicted):\n",
        "          print('\\t{:<10} {:>15}'.format(t, idx2tag[p.item()]))\n",
        "\n",
        "    return tokens, predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1SttOeM3u14"
      },
      "source": [
        "ner = NER(model=model, \n",
        "          trainloader=trainloader, \n",
        "          validationloader=validationloader,\n",
        "          optimizer_cls=Adam,\n",
        "          loss_fn_cls=nn.CrossEntropyLoss)\n",
        " \n",
        "ner.train(5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}